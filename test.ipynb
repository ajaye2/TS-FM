{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchsummary\n",
    "# !pip install torchinfo\n",
    "# !pip install lumnisfactors\n",
    "# !pip install matplotlib\n",
    "# !pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abuj/opt/anaconda3/envs/baseline/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/abuj/opt/anaconda3/envs/baseline/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <320D718F-E2FD-3687-B2F0-E83CF97743B1> /Users/abuj/opt/anaconda3/envs/baseline/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <ADB29998-4917-3D35-B2A2-77968871B420> /Users/abuj/opt/anaconda3/envs/baseline/lib/python3.8/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/Users/abuj/opt/anaconda3/envs/baseline/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import grequests\n",
    "\n",
    "from src.mvts_transformer.ts_transformer import TSTransformerEncoder, model_factory\n",
    "from src.utils import create_3d_array, standardize, rolling_mean_diff\n",
    "from src.projection_layers import LSTMMaskedAutoencoderProjection\n",
    "from src.dataset import TSDataset, ImputationDataset\n",
    "from src.dataloader import TSDataLoader\n",
    "from src.TFC.dataloader import TFCDataset\n",
    "from src.encoders import TFC\n",
    "from src.configs import Configs\n",
    "from src.RevIN import RevIN\n",
    "from src.TSFM import TSFM\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.fft as fft\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torchinfo import summary\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lumnisfactors import LumnisFactors\n",
    "from KEYS import LUMNIS_API_KEY\n",
    "\n",
    "factorName          = \"price\"\n",
    "lumnis              = LumnisFactors(LUMNIS_API_KEY)\n",
    "temp_df_btc_raw     = lumnis.get_historical_data(factorName, \"binance\", \"btcusdt\",  \"hour\", \"2021-01-23\", \"2023-04-16\")\n",
    "temp_df_eth_raw     = lumnis.get_historical_data(factorName, \"binance\", \"ethusdt\",  \"hour\", \"2021-01-23\", \"2023-04-16\")\n",
    "temp_df_xmr_raw     = lumnis.get_historical_data(factorName, \"binance\", \"xmrusdt\",  \"hour\", \"2021-01-23\", \"2023-04-16\")\n",
    "ob_df_raw           = lumnis.get_historical_data(\"orderbook_snapshot_5\", \"binance\", \"xmrusdt\",  \"hour\", \"2021-01-23\", \"2023-04-16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df_btc         = rolling_mean_diff(temp_df_btc_raw, [ 5, 25, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], type='standard')\n",
    "temp_df_eth         = rolling_mean_diff(temp_df_eth_raw, [ 5, 25, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], type='standard')\n",
    "temp_df_xmr         = rolling_mean_diff(temp_df_xmr_raw, [ 5, 25, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], type='standard')\n",
    "\n",
    "\n",
    "cols                = temp_df_btc.columns #['close', 'volume'] #\n",
    "max_seq_len         = 50\n",
    "\n",
    "btc_array           = create_3d_array(temp_df_btc[cols], temp_df_btc.index, max_seq_len)\n",
    "eth_array           = create_3d_array(temp_df_eth[cols], temp_df_eth.index, max_seq_len)\n",
    "xmr_array           = create_3d_array(temp_df_xmr[cols], temp_df_xmr.index, max_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your data as a dictionary\n",
    "data_dict = {\n",
    "    'dataset_btc': torch.from_numpy( btc_array).to(torch.float32),\n",
    "    'dataset_eth': torch.from_numpy( eth_array).to(torch.float32),\n",
    "    'dataset_xmr': torch.from_numpy( xmr_array).to(torch.float32)\n",
    "}\n",
    "\n",
    "# Create instances of TSDataset for each dataset\n",
    "datasets = {name: ImputationDataset(data) for name, data in data_dict.items()}\n",
    "\n",
    "# Create an instance of the custom data loader\n",
    "ts_data_loader = TSDataLoader(datasets, batch_size=64, max_len=max_seq_len)\n",
    "\n",
    "num_epochs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_shapes_dict  = {name: data.shape[1:] for name, data in data_dict.items()}\n",
    "\n",
    "encoder_configs         = Configs(TSlength_aligned=max_seq_len, \n",
    "                                    features_len=data_dict['dataset_btc'].shape[-1], \n",
    "                                    features_len_f=data_dict['dataset_btc'].shape[-1], \n",
    "                                    n_head=1,\n",
    "                                    dim_feedforward=128,\n",
    "                                    num_transformer_layers=1,\n",
    "                                    encoder_layer_dims=128,\n",
    "                                    linear_encoder_dim=256,\n",
    "                                    channel_output_size=10,\n",
    "                                    time_output_size=10,\n",
    "                                    d_model=128,\n",
    "                                    pos_encoding='learnable',\n",
    "                                    transformer_activation='gelu',\n",
    "                                    transformer_normalization_layer='BatchNorm',\n",
    "                                    freeze=False,\n",
    "                                )\n",
    "\n",
    "tsfm                    = TSFM(input_data_shapes_dict, \n",
    "                                batch_size=128, \n",
    "                                lr=1e-3, \n",
    "                                log=True, \n",
    "                                device='cpu',\n",
    "                                max_seq_length=max_seq_len,\n",
    "                                encoder_config=encoder_configs\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abuj/Documents/GitHub/TS-FM/src/TSFM.py:133: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/IndexingUtils.h:28.)\n",
      "  train_data             = train_data[~np.isnan(train_data).all(axis=2).all(axis=1)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'is_causal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m      1\u001b[0m warmup_config_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdataset_btc\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[1;32m      3\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m128\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     }\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     19\u001b[0m data_set_type \u001b[39m=\u001b[39m ImputationDataset \u001b[39m# Make the ability to infer dataset type based on projection layer \u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m loss          \u001b[39m=\u001b[39m tsfm\u001b[39m.\u001b[39;49mfit(data_dict, n_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, warmup_projection_layers\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, log\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, warmup_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, warmup_config_kwargs\u001b[39m=\u001b[39;49mwarmup_config_kwargs, warmup_batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, data_set_type\u001b[39m=\u001b[39;49mdata_set_type)\n",
      "File \u001b[0;32m~/Documents/GitHub/TS-FM/src/TSFM.py:199\u001b[0m, in \u001b[0;36mTSFM.fit\u001b[0;34m(self, train_data_dict, labels, n_epochs, n_iters, verbose, shuffle, warmup_projection_layers, warmup_epochs, log, subset, configs, training_mode, warmup_config_kwargs, data_set_type, warmup_batch_size)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39mfor\u001b[39;00m dataset_name, data \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 199\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(data, dataset_name, optimizer, enocder_dataset_type)\n\u001b[1;32m    200\u001b[0m     cum_loss_dict[dataset_name] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    202\u001b[0m n_epoch_iters \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/TS-FM/src/TSFM.py:224\u001b[0m, in \u001b[0;36mTSFM.train_step\u001b[0;34m(self, data, dataset_name, optimizer, data_set_type)\u001b[0m\n\u001b[1;32m    220\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder_layer \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mTFC\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 224\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_step_TFC(data, dataset_name, data_set_type)\n\u001b[1;32m    226\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    227\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Documents/GitHub/TS-FM/src/TSFM.py:248\u001b[0m, in \u001b[0;36mTSFM._train_step_TFC\u001b[0;34m(self, batch, dataset_name, data_set_type)\u001b[0m\n\u001b[1;32m    245\u001b[0m aug1_f                              \u001b[39m=\u001b[39m DataTransform_FD(x_data_f, config)\n\u001b[1;32m    247\u001b[0m \u001b[39m# Produce embeddings\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m h_t, z_t, h_f, z_f                  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_encoder(x_data, x_data_f, padding_masks)\n\u001b[1;32m    249\u001b[0m h_t_aug, z_t_aug, h_f_aug, z_f_aug  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encoder(aug1, aug1_f, padding_masks)\n\u001b[1;32m    251\u001b[0m \u001b[39m# Compute Pre-train loss\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[39m# NTXentLoss: normalized temperature-scaled cross entropy loss. From SimCLR\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/baseline/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/TS-FM/src/encoders.py:74\u001b[0m, in \u001b[0;36mTFC.forward\u001b[0;34m(self, x_in_t, x_in_f, padding_masks)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x_in_t: torch\u001b[39m.\u001b[39mTensor, x_in_f: torch\u001b[39m.\u001b[39mTensor, padding_masks: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m    Perform forward pass for the TFC module.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m        Tuple containing h_time, z_time, h_freq, and z_freq tensors.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder_t(x_in_t, padding_masks)\n\u001b[1;32m     75\u001b[0m     h_time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madaptive_pool_t(x)\n\u001b[1;32m     77\u001b[0m     z_time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprojector_t(h_time)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/baseline/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/TS-FM/src/mvts_transformer/ts_transformer.py:241\u001b[0m, in \u001b[0;36mTSTransformerEncoder.forward\u001b[0;34m(self, X, padding_masks)\u001b[0m\n\u001b[1;32m    239\u001b[0m inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_enc(inp)  \u001b[39m# add positional encoding\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m# NOTE: logic for padding masks is reversed to comply with definition in MultiHeadAttention, TransformerEncoderLayer\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder(inp, src_key_padding_mask\u001b[39m=\u001b[39;49m\u001b[39m~\u001b[39;49mpadding_masks)  \u001b[39m# (seq_length, batch_size, d_model)\u001b[39;00m\n\u001b[1;32m    242\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(output)  \u001b[39m# the output transformer encoder/decoder embeddings don't include non-linearity\u001b[39;00m\n\u001b[1;32m    243\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)  \u001b[39m# (batch_size, seq_length, d_model)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/baseline/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/baseline/lib/python3.8/site-packages/torch/nn/modules/transformer.py:306\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    303\u001b[0m is_causal \u001b[39m=\u001b[39m make_causal\n\u001b[1;32m    305\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 306\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, is_causal\u001b[39m=\u001b[39;49mis_causal, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[1;32m    308\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    309\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/baseline/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'is_causal'"
     ]
    }
   ],
   "source": [
    "warmup_config_kwargs = {\n",
    "    \"dataset_btc\": {\n",
    "        \"batch_size\": 128,\n",
    "        \"input_channels\": data_dict['dataset_btc'].shape[-1],\n",
    "        \"timesteps\": data_dict['dataset_btc'].shape[1],\n",
    "    },\n",
    "    \"dataset_eth\": {\n",
    "        \"batch_size\": 128,\n",
    "        \"input_channels\": data_dict['dataset_eth'].shape[-1],\n",
    "        \"timesteps\": data_dict['dataset_eth'].shape[1],\n",
    "    },\n",
    "    \"dataset_xmr\": {\n",
    "        \"batch_size\": 128,\n",
    "        \"input_channels\": data_dict['dataset_xmr'].shape[-1],\n",
    "        \"timesteps\": data_dict['dataset_xmr'].shape[1],\n",
    "    }\n",
    "}\n",
    "\n",
    "data_set_type = ImputationDataset # Make the ability to infer dataset type based on projection layer \n",
    "loss          = tsfm.fit(data_dict, n_epochs=10, warmup_projection_layers=False, log=True, verbose=True, shuffle=True, warmup_epochs=10, warmup_config_kwargs=warmup_config_kwargs, warmup_batch_size=128, data_set_type=data_set_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m esm \u001b[39m=\u001b[39m EventSamplingModule(input_size, event_embedding_size)\n\u001b[1;32m     35\u001b[0m \u001b[39m# Get event embeddings\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m event_embeddings \u001b[39m=\u001b[39m esm(time_series_data)\n\u001b[1;32m     37\u001b[0m \u001b[39mprint\u001b[39m(event_embeddings\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/baseline/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m, in \u001b[0;36mEventSamplingModule.forward\u001b[0;34m(self, time_series)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, time_series):\n\u001b[1;32m     19\u001b[0m     event_indices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mz_score_analysis(time_series)\n\u001b[0;32m---> 20\u001b[0m     event_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevent_embedding(event_indices)\n\u001b[1;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m event_embeddings\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/baseline/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/baseline/lib/python3.8/site-packages/torch/nn/modules/sparse.py:160\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    161\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    162\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/baseline/lib/python3.8/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class EventSamplingModule(nn.Module):\n",
    "    def __init__(self, input_size, event_embedding_size, z_score_threshold=2.0):\n",
    "        super(EventSamplingModule, self).__init__()\n",
    "        self.z_score_threshold = z_score_threshold\n",
    "        self.event_embedding = nn.Embedding(input_size, event_embedding_size)\n",
    "\n",
    "    def z_score_analysis(self, time_series):\n",
    "        means = time_series.mean(dim=1, keepdim=True)\n",
    "        stds = time_series.std(dim=1, keepdim=True)\n",
    "        z_scores = torch.abs((time_series - means) / stds)\n",
    "        event_indices = (z_scores > self.z_score_threshold).long()\n",
    "        return event_indices\n",
    "\n",
    "    def forward(self, time_series):\n",
    "        event_indices = self.z_score_analysis(time_series)\n",
    "        event_embeddings = self.event_embedding(event_indices)\n",
    "        return event_embeddings\n",
    "\n",
    "# Example usage\n",
    "input_size = 1\n",
    "event_embedding_size = 10\n",
    "time_series_length = 50\n",
    "batch_size = 32\n",
    "\n",
    "# Generate synthetic time series data\n",
    "time_series_data = torch.randn(batch_size, time_series_length, input_size)\n",
    "\n",
    "# Initialize Event Sampling Module\n",
    "esm = EventSamplingModule(input_size, event_embedding_size)\n",
    "\n",
    "# Get event embeddings\n",
    "event_embeddings = esm(time_series_data)\n",
    "print(event_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
