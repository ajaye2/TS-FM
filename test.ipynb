{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchsummary\n",
    "# !pip install torchinfo\n",
    "# !pip install lumnisfactors\n",
    "# !pip install matplotlib\n",
    "# !pip install torchmetrics\n",
    "# !conda install cudnn=8.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/baseline/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import grequests\n",
    "\n",
    "from src.mvts_transformer.ts_transformer import TSTransformerEncoder, model_factory\n",
    "from src.utils import create_3d_array, standardize, rolling_mean_diff, generate_univariate_data_labels, generate_data_labels_from_3d_array, get_train_val_test_array\n",
    "from src.projection_layers import LSTMMaskedAutoencoderProjection\n",
    "from src.dataset import TSDataset, ImputationDataset\n",
    "from src.dataloader import TSDataLoader\n",
    "from src.TFC.dataloader import TFCDataset\n",
    "from src.encoders import TFC\n",
    "from src.configs import Configs, ModelConfig\n",
    "from src.RevIN import RevIN\n",
    "from src.TSFM import TSFM\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.fft as fft\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torchinfo import summary\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import sys\n",
    "import os\n",
    "print(os.cpu_count())\n",
    "sys.setrecursionlimit(5000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.13.1+cu117\n",
      "CUDA available: True\n",
      "Torch version: 1.13.1+cu117\n",
      "CUDA available: True\n",
      "cuDNN version: 8401\n"
     ]
    }
   ],
   "source": [
    "# !conda uninstall pytorch torchvision -y\n",
    "# !pip install torch torchvision -f https://download.pytorch.org/whl/cu111/torch_stable.html\n",
    "import torch\n",
    "try:\n",
    "    !unset LD_LIBRARY_PATH\n",
    "    print(\"Torch version:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
    "except:\n",
    "    !unset LD_LIBRARY_PATH\n",
    "    print(\"Torch version:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"cuDNN version:\", torch.backends.cudnn.version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lumnisfactors import LumnisFactors\n",
    "from KEYS import LUMNIS_API_KEY\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import os\n",
    "    \n",
    "\n",
    "\n",
    "# [\"ADAUSD\", \"BTCUSD\", \"DASHUSD\", \"DOGEUSD\", \"DOTUSD\", \"ETHUSD\", \"LTCUSD\", \"NEOUSD\", \"XMRUSD\", \"XRPUSD\", \"XBTUSD\", \"SOLUSD\", \"BNBUSD\", \"AVAXUSD\" \"MATICUSDâ€] \n",
    "\n",
    "factorName          = \"price\"\n",
    "lumnis              = LumnisFactors(LUMNIS_API_KEY)\n",
    "path_to_data = \"/home/ec2-user/TS-FM/src/data/\"\n",
    "\n",
    "btc_file = Path(path_to_data + \"btc.csv\")\n",
    "eth_file = Path(path_to_data + \"eth.csv\")\n",
    "xmr_file = Path(path_to_data + \"xmr.csv\")\n",
    "ada_file = Path(path_to_data + \"ada.csv\")\n",
    "doge_file = Path(path_to_data + \"doge.csv\")\n",
    "bnb_file = Path(path_to_data + \"bnb.csv\")\n",
    "dot_file = Path(path_to_data + \"dot.csv\")\n",
    "ltc_file = Path(path_to_data + \"ltc.csv\")\n",
    "dash_file = Path(path_to_data + \"dash.csv\")\n",
    "neo_file = Path(path_to_data + \"neo.csv\")\n",
    "xrp_file = Path(path_to_data + \"xrp.csv\")\n",
    "sol_file = Path(path_to_data + \"sol.csv\")\n",
    "\n",
    "if btc_file.is_file():\n",
    "    temp_df_btc_raw     = pd.read_csv(path_to_data + \"btc.csv\").set_index(\"Unnamed: 0\")\n",
    "else:\n",
    "    temp_df_btc_raw     = lumnis.get_historical_data(factorName, \"binance\", \"btcusdt\",  \"hour\", \"2021-01-23\", \"2023-04-16\")\n",
    "    temp_df_btc_raw.to_csv(path_to_data + \"btc.csv\")\n",
    "\n",
    "if eth_file.is_file():\n",
    "    temp_df_eth_raw     = pd.read_csv(path_to_data + \"eth.csv\").set_index(\"Unnamed: 0\")\n",
    "else:\n",
    "    temp_df_eth_raw     = lumnis.get_historical_data(factorName, \"binance\", \"ethusdt\",  \"hour\", \"2021-01-23\", \"2023-04-16\")\n",
    "    temp_df_eth_raw.to_csv(path_to_data + \"eth.csv\")\n",
    "\n",
    "if xmr_file.is_file():\n",
    "    temp_df_xmr_raw     = pd.read_csv(path_to_data + \"xmr.csv\").set_index(\"Unnamed: 0\")\n",
    "else:\n",
    "    temp_df_xmr_raw     = lumnis.get_historical_data(factorName, \"binance\", \"xmrusdt\",  \"hour\", \"2021-01-23\", \"2023-04-16\")\n",
    "    temp_df_xmr_raw.to_csv(path_to_data + \"xmr.csv\")\n",
    "\n",
    "if ada_file.is_file():\n",
    "    temp_df_ada_raw     = pd.read_csv(path_to_data + \"ada.csv\").set_index(\"Unnamed: 0\")\n",
    "else:\n",
    "    temp_df_ada_raw     = lumnis.get_historical_data(factorName, \"binance\", \"adausdt\",  \"hour\", \"2019-04-01\", \"2023-05-01\")\n",
    "    temp_df_ada_raw.to_csv(path_to_data + \"ada.csv\")\n",
    "\n",
    "if doge_file.is_file():\n",
    "    temp_df_doge_raw     = pd.read_csv(path_to_data + \"doge.csv\").set_index(\"Unnamed: 0\")\n",
    "else:\n",
    "    temp_df_doge_raw     = lumnis.get_historical_data(factorName, \"binance\", \"dogeusdt\",  \"hour\", \"2019-04-01\", \"2023-05-01\")\n",
    "    temp_df_doge_raw.to_csv(path_to_data + \"doge.csv\")\n",
    "\n",
    "if bnb_file.is_file():\n",
    "    temp_df_bnb_raw     = pd.read_csv(path_to_data + \"bnb.csv\").set_index(\"Unnamed: 0\")\n",
    "else:\n",
    "    temp_df_bnb_raw     = lumnis.get_historical_data(factorName, \"binance\", \"bnbusdt\",  \"hour\", \"2019-04-01\", \"2023-05-01\")\n",
    "    temp_df_bnb_raw.to_csv(path_to_data + \"bnb.csv\")\n",
    "\n",
    "if dot_file.is_file():\n",
    "    temp_df_dot_raw     = pd.read_csv(path_to_data + \"dot.csv\").set_index(\"Unnamed: 0\")\n",
    "else:\n",
    "    temp_df_dot_raw     = lumnis.get_historical_data(factorName, \"binance\", \"dotusdt\",  \"hour\", \"2019-04-01\", \"2023-05-01\")\n",
    "    temp_df_dot_raw.to_csv(path_to_data + \"dot.csv\")\n",
    "\n",
    "if ltc_file.is_file():\n",
    "    temp_df_ltc_raw     = pd.read_csv(path_to_data + \"ltc.csv\").set_index(\"Unnamed: 0\")\n",
    "else:\n",
    "    temp_df_ltc_raw     = lumnis.get_historical_data(factorName, \"binance\", \"ltcusdt\",  \"hour\", \"2019-04-01\", \"2023-05-01\")\n",
    "    temp_df_ltc_raw.to_csv(path_to_data + \"ltc.csv\")\n",
    "\n",
    "if dash_file.is_file():\n",
    "    temp_df_dash_raw     = pd.read_csv(path_to_data + \"dash.csv\").set_index(\"Unnamed: 0\")\n",
    "else:\n",
    "    temp_df_dash_raw     = lumnis.get_historical_data(factorName, \"binance\", \"dashusdt\",  \"hour\", \"2019-04-01\", \"2023-05-01\")\n",
    "    temp_df_dash_raw.to_csv(path_to_data + \"dash.csv\")\n",
    "\n",
    "if neo_file.is_file():\n",
    "    temp_df_neo_raw     = pd.read_csv(path_to_data + \"neo.csv\").set_index(\"Unnamed: 0\")\n",
    "else:\n",
    "    temp_df_neo_raw     = lumnis.get_historical_data(factorName, \"binance\", \"neousdt\",  \"hour\", \"2019-04-01\", \"2023-05-01\")\n",
    "    temp_df_neo_raw.to_csv(path_to_data + \"neo.csv\")\n",
    "\n",
    "if xrp_file.is_file():\n",
    "    temp_df_xrp_raw     = pd.read_csv(path_to_data + \"xrp.csv\").set_index(\"Unnamed: 0\")\n",
    "else:\n",
    "    temp_df_xrp_raw     = lumnis.get_historical_data(factorName, \"binance\", \"xrpusdt\",  \"hour\", \"2019-04-01\", \"2023-05-01\")\n",
    "    temp_df_xrp_raw.to_csv(path_to_data + \"xrp.csv\")\n",
    "\n",
    "if sol_file.is_file():\n",
    "    temp_df_sol_raw     = pd.read_csv(path_to_data + \"sol.csv\").set_index(\"Unnamed: 0\")\n",
    "else:\n",
    "    temp_df_sol_raw     = lumnis.get_historical_data(factorName, \"binance\", \"solusdt\",  \"hour\", \"2019-04-01\", \"2023-05-01\")\n",
    "    temp_df_sol_raw.to_csv(path_to_data + \"sol.csv\")\n",
    "\n",
    "# TODO: Add resample and fillna with ffill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26968, 150, 104) (3371, 150, 104) (3372, 150, 104)\n"
     ]
    }
   ],
   "source": [
    "all_data_dict_df = {\n",
    "    \"btc\"   : temp_df_btc_raw,\n",
    "    # \"eth\"   : temp_df_eth_raw,\n",
    "    # \"xmr\"   : temp_df_xmr_raw,\n",
    "    # \"ada\"   : temp_df_ada_raw,\n",
    "    # \"bnb\"   : temp_df_bnb_raw,\n",
    "\n",
    "    # \"doge\"  : temp_df_doge_raw,\n",
    "    # \"dot\"   : temp_df_dot_raw,\n",
    "    # \"ltc\"   : temp_df_ltc_raw,\n",
    "    # \"dash\"  : temp_df_dash_raw,\n",
    "    # \"neo\"   : temp_df_neo_raw,\n",
    "    # \"xrp\"   : temp_df_xrp_raw,\n",
    "    # \"sol\"   : temp_df_sol_raw\n",
    "    \n",
    "}\n",
    "\n",
    "all_data_rolling_df ={}\n",
    "type_rol = 'standard'\n",
    "\n",
    "for key, value in all_data_dict_df.items():\n",
    "    all_data_rolling_df[key] = rolling_mean_diff(value, [ 5, 25, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000 ], type=type_rol)\n",
    "\n",
    "data_dict_array  = {}\n",
    "max_seq_len     = 150\n",
    "\n",
    "for key, value in all_data_rolling_df.items():\n",
    "    array, array_idxs = create_3d_array(value, value.index, max_seq_len)\n",
    "    data_dict_array[key + \"_data\"] = array\n",
    "    data_dict_array[key + \"_idxs\"] = array_idxs\n",
    "\n",
    "    train_array, val_array, test_array = get_train_val_test_array(array, 0.8, 0.1, 0.1)\n",
    "    data_dict_array[key + \"_train_data\"] = train_array\n",
    "    data_dict_array[key + \"_val_data\"] = val_array\n",
    "    data_dict_array[key + \"_test_data\"] = test_array\n",
    "\n",
    "    train_idxs, val_idxs, test_idxs = get_train_val_test_array(array_idxs, 0.8, 0.1, 0.1)\n",
    "    data_dict_array[key + \"_train_idxs\"] = train_idxs\n",
    "    data_dict_array[key + \"_val_idxs\"] = val_idxs\n",
    "    data_dict_array[key + \"_test_idxs\"] = test_idxs\n",
    "\n",
    "    print(train_array.shape, val_array.shape, test_array.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.dataset import preprocess_sample, collate_unsuperv, noise_mask\n",
    "# import multiprocessing\n",
    "# def preprocess_imputation_dataset(data, mean_mask_length=3, masking_ratio=0.15,\n",
    "#                  mode='separate', distribution='geometric', exclude_feats=None, max_len=None,\n",
    "#                  mask_compensation=False, pad_inputs=False, mask_inputs=True):\n",
    "    \n",
    "#     num_workers = 1#os.cpu_count()\n",
    "#     with multiprocessing.Pool(os.cpu_count()) as pool:\n",
    "#         data_with_masks = list(pool.map(preprocess_sample, [(data[i], masking_ratio, mean_mask_length,\n",
    "#                                                                 mode, distribution, exclude_feats)\n",
    "#                                                                 for i in range(len(data))]))\n",
    "\n",
    "#     X, targets, target_masks, padding_masks = collate_unsuperv(data_with_masks, max_len, mask_compensation,\n",
    "#                                                                 pad_inputs, mask_inputs)\n",
    "\n",
    "#     preprocessed_data = []\n",
    "#     for i in range(len(data)):\n",
    "#         preprocessed_sample = (X[i], targets[i], target_masks[i], padding_masks[i])\n",
    "#         preprocessed_data.append(preprocessed_sample)\n",
    "\n",
    "#     return preprocessed_data\n",
    "\n",
    "        \n",
    "# preprocessed_data = preprocess_imputation_dataset(data_dict_array[\"btc_train_data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your data as a dictionary\n",
    "data_dict = {}\n",
    "for key in data_dict_array.keys():\n",
    "    if '_train_data' in key:\n",
    "        asset = key.split(\"_train_data\")[0]\n",
    "        data_dict[\"dataset_\" + asset] = data_dict_array[key]\n",
    "\n",
    "# Convert numpy arrays to torch tensors\n",
    "for key in data_dict.keys():\n",
    "    if type(data_dict[key]) == dict: \n",
    "        data_dict[key]['data'] = torch.from_numpy( data_dict[key]['data'] ).to(torch.float32)\n",
    "        data_dict[key]['labels'] = torch.from_numpy( data_dict[key]['labels'] ).to(torch.float32)\n",
    "    else:\n",
    "        data_dict[key] = torch.from_numpy( data_dict[key] ).to(torch.float32)\n",
    "           \n",
    "# Create instances of TSDataset for each dataset\n",
    "datasets = { name: (TSDataset(data['data'], data['labels'], max_len=max_seq_len, shuffle=True) if type(data)==dict\n",
    "          else ImputationDataset(data, masking_ratio=0.25)) for name, data in data_dict.items() }\n",
    "\n",
    "# Create an instance of the custom data loader\n",
    "ts_data_loader = TSDataLoader(datasets, batch_size=512, max_len=max_seq_len, collate_fn='unsuperv', shuffle=False)\n",
    "\n",
    "#Takes 6 mins to load 43371 samples with 150 timesteps each, and 104 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "input_data_shapes_dict  = {name: data['data'].shape[1:] if type(data)==dict else data.shape[1:] for name, data in data_dict.items()}\n",
    "# input_data_shapes_dict = {\"temp\": (max_seq_len, 104)}\n",
    "\n",
    "DEVICE                  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MAX_SEQ_LENGTH          = max_seq_len\n",
    "ENCODER_LAYER_DIMS      = 32\n",
    "PROJECTION_DIMS         = 32\n",
    "\n",
    "max_seq_len = 50\n",
    "model_config = ModelConfig( task_name='encoder', enc_in=PROJECTION_DIMS, dec_in=PROJECTION_DIMS,  c_out=ENCODER_LAYER_DIMS,\n",
    "                 d_model=64, n_heads=4, e_layers=2,  d_layers=2,  d_ff=32,\n",
    "                 dropout=0.1, activation='relu',  factor=5, freq='h',\n",
    "                 embed='fixed', output_attention=False, distil=True,\n",
    "                 pred_len=max_seq_len, label_len=1, num_class=1, \n",
    "                 seq_len=max_seq_len,\n",
    "                 top_k=1, \n",
    "                 use_temporal_embed=False,\n",
    "                 p_hidden_dims=[64, 64],\n",
    "                 p_hidden_layers=2,\n",
    "                 moving_avg=28, \n",
    "                 individual=False, \n",
    "                 num_kernels=3,\n",
    "                 max_len=max_seq_len,\n",
    "                 use_mask=False,\n",
    "                ) \n",
    "\n",
    "encoder_configs         = Configs(TSlength_aligned=max_seq_len, \n",
    "                                    features_len=PROJECTION_DIMS, \n",
    "                                    features_len_f=PROJECTION_DIMS, \n",
    "                                    encoder_layer_dims=ENCODER_LAYER_DIMS,\n",
    "                                    dim_feedforward=128,\n",
    "                                    linear_encoder_dim=256,\n",
    "                                    channel_output_size=10,\n",
    "                                    time_output_size=10,\n",
    "                                    d_model=128,\n",
    "                                    num_transformer_layers=1,\n",
    "                                    n_head=1,\n",
    "                                    pos_encoding='learnable',\n",
    "                                    transformer_activation='gelu',\n",
    "                                    transformer_normalization_layer='BatchNorm',\n",
    "                                    freeze=False,\n",
    "                                    device=DEVICE,\n",
    "                                )\n",
    "\n",
    "\n",
    "\n",
    "tsfm                    = TSFM(input_data_shapes_dict, \n",
    "                                model_name=\"INIT_TEST_V2\",\n",
    "                                device=DEVICE,\n",
    "                                max_seq_length=max_seq_len,\n",
    "                                encoder_config=encoder_configs,\n",
    "                                projection_layer_dims=PROJECTION_DIMS,\n",
    "                                # type_of_encoder=\"non_stationary_transformer\",\n",
    "                                use_revin=False,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_config_kwargs = {\n",
    "    \"dataset_btc\": {\n",
    "        \"batch_size\": 512,\n",
    "        \"input_channels\": data_dict['dataset_btc']['data'].shape[-1] if type(data_dict['dataset_btc'])==dict else data_dict['dataset_btc'].shape[-1],\n",
    "        \"timesteps\": data_dict['dataset_btc']['data'].shape[1] if type(data_dict['dataset_btc'])==dict else data_dict['dataset_btc'].shape[1],\n",
    "        \"data_set_type\": ImputationDataset,\n",
    "        \"num_epochs\": 30,\n",
    "        \"lr\": 1e-4,\n",
    "        \"kwargs\": {\n",
    "            \"verbose\": False,\n",
    "        }\n",
    "    },\n",
    "    \"dataset_eth\": {\n",
    "        \"batch_size\": 512,\n",
    "        \"input_channels\": data_dict['dataset_eth']['data'].shape[-1] if type(data_dict['dataset_eth'])==dict else data_dict['dataset_eth'].shape[-1],\n",
    "        \"timesteps\": data_dict['dataset_eth']['data'].shape[1]  if type(data_dict['dataset_eth'])==dict else data_dict['dataset_eth'].shape[1],\n",
    "        \"data_set_type\": ImputationDataset,\n",
    "        \"num_epochs\": 30,\n",
    "        \"lr\": 1e-4,\n",
    "        \"kwargs\": {\n",
    "            \"verbose\": False,\n",
    "        }\n",
    "    },\n",
    "    \"dataset_xmr\": {\n",
    "        \"batch_size\": 512,\n",
    "        \"input_channels\": data_dict['dataset_xmr']['data'].shape[-1] if type(data_dict['dataset_xmr'])==dict else data_dict['dataset_xmr'].shape[-1],\n",
    "        \"timesteps\": data_dict['dataset_xmr']['data'].shape[1] if type(data_dict['dataset_xmr'])==dict else data_dict['dataset_xmr'].shape[1],\n",
    "        \"data_set_type\": ImputationDataset,\n",
    "        \"num_epochs\": 30,\n",
    "        \"lr\": 1e-4,\n",
    "        \"kwargs\": {\n",
    "            \"verbose\": False,\n",
    "        }\n",
    "    },\n",
    "    \"dataset_ada\": {\n",
    "        \"batch_size\": 512,\n",
    "        \"input_channels\": data_dict['dataset_ada']['data'].shape[-1] if type(data_dict['dataset_ada'])==dict else data_dict['dataset_ada'].shape[-1],\n",
    "        \"timesteps\": data_dict['dataset_ada']['data'].shape[1] if type(data_dict['dataset_ada'])==dict else data_dict['dataset_ada'].shape[1],\n",
    "        \"data_set_type\": ImputationDataset,\n",
    "        \"num_epochs\": 30,\n",
    "        \"lr\": 1e-4,\n",
    "        \"kwargs\": {\n",
    "            \"verbose\": False,\n",
    "        }\n",
    "    },\n",
    "    \"dataset_bnb\": {\n",
    "        \"batch_size\": 512,\n",
    "        \"input_channels\": data_dict['dataset_bnb']['data'].shape[-1] if type(data_dict['dataset_bnb'])==dict else data_dict['dataset_bnb'].shape[-1],\n",
    "        \"timesteps\": data_dict['dataset_bnb']['data'].shape[1] if type(data_dict['dataset_bnb'])==dict else data_dict['dataset_bnb'].shape[1],\n",
    "        \"data_set_type\": ImputationDataset,\n",
    "        \"num_epochs\": 30,\n",
    "        \"lr\": 1e-4,\n",
    "        \"kwargs\": {\n",
    "            \"verbose\": False,\n",
    "        }\n",
    "    },\n",
    "    # \"dataset_ltc\": { \n",
    "    #     \"batch_size\": 512,\n",
    "    #     \"input_channels\": data_dict['dataset_ltc']['data'].shape[-1] if type(data_dict['dataset_ltc'])==dict else data_dict['dataset_ltc'].shape[-1],\n",
    "    #     \"timesteps\": data_dict['dataset_ltc']['data'].shape[1] if type(data_dict['dataset_ltc'])==dict else data_dict['dataset_ltc'].shape[1],\n",
    "    #     \"data_set_type\": ImputationDataset,\n",
    "    #     \"num_epochs\": 30,\n",
    "    #     \"lr\": 1e-4,\n",
    "    #     \"kwargs\": {\n",
    "    #         \"verbose\": False,\n",
    "    #     }\n",
    "    # },\n",
    "\n",
    "    # \"univariate\": {\n",
    "    #     \"batch_size\": 512,\n",
    "    #     \"input_channels\": data_dict['univariate']['data'].shape[-1],\n",
    "    #     \"timesteps\": data_dict['univariate']['data'].shape[1],\n",
    "    #     \"data_set_type\": TSDataset,\n",
    "    #     \"num_epochs\": 30,\n",
    "    #     \"lr\": 1e-4,\n",
    "    #     \"kwargs\": {\n",
    "    #         \"verbose\": False,\n",
    "    #     }\n",
    "    # }\n",
    "}\n",
    "\n",
    "# TODO: Add learning rate to warmup config kwargs\n",
    "\n",
    "N_EPOCHS                 = 50\n",
    "WARMUP_EPOCHS            = 35\n",
    "WARMUP_BATCH_SIZE        = 512\n",
    "WARMUP_PROJECTION_LAYERS = True\n",
    "BATCH_SIZE               = 512\n",
    "LR                       = 1e-4\n",
    "LOG                      = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: - CHANGE ENCODER TYPE, - USE MORE DATA, - LOOK AT ENCODE FUNCT (are my using revin?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points: 133622 from dataset_btc, dataset_eth, dataset_xmr, dataset_ada, dataset_bnb\n",
      "Warming up with 52 batches of size 512. Dataset name dataset_btc.\n",
      "Epoch: 0, Loss: 0.9579390424948472\n",
      "Epoch: 1, Loss: 0.9500822046628365\n",
      "Epoch: 2, Loss: 0.9370046934256187\n",
      "Epoch: 3, Loss: 0.9138270582144077\n",
      "Epoch: 4, Loss: 0.8825798172217149\n",
      "Epoch: 5, Loss: 0.8455735926444714\n",
      "Epoch: 6, Loss: 0.8068130520673898\n",
      "Epoch: 7, Loss: 0.7684087352110789\n",
      "Epoch: 8, Loss: 0.7300820763294513\n",
      "Epoch: 9, Loss: 0.6930629014968872\n",
      "Epoch: 10, Loss: 0.658109473494383\n",
      "Epoch: 11, Loss: 0.6259821057319641\n",
      "Epoch: 12, Loss: 0.5976645327531375\n",
      "Epoch: 13, Loss: 0.5730036852451471\n",
      "Epoch: 14, Loss: 0.5515064367881188\n",
      "Epoch: 15, Loss: 0.5327673325171838\n",
      "Epoch: 16, Loss: 0.5163019087452155\n",
      "Epoch: 17, Loss: 0.5010624654017962\n",
      "Epoch: 18, Loss: 0.48724626233944524\n",
      "Epoch: 19, Loss: 0.47452133951278835\n",
      "Epoch: 20, Loss: 0.4626724553795961\n",
      "Epoch: 21, Loss: 0.45121635553928524\n",
      "Epoch: 22, Loss: 0.43991481913970065\n",
      "Epoch: 23, Loss: 0.4290271991720566\n",
      "Epoch: 24, Loss: 0.4181289179967\n",
      "Epoch: 25, Loss: 0.40739085697210753\n",
      "Epoch: 26, Loss: 0.39700229523273617\n",
      "Epoch: 27, Loss: 0.38665267538565856\n",
      "Epoch: 28, Loss: 0.37709656873574626\n",
      "Epoch: 29, Loss: 0.3681303537808932\n",
      "Epoch: 30, Loss: 0.3598308213628255\n",
      "Epoch: 31, Loss: 0.35227493483286637\n",
      "Epoch: 32, Loss: 0.3455529665717712\n",
      "Epoch: 33, Loss: 0.3393440292431758\n",
      "Epoch: 34, Loss: 0.33375441053738963\n",
      "Finished warmup in 68.12151455879211 seconds.\n",
      "Warming up with 51 batches of size 512. Dataset name dataset_eth.\n",
      "Epoch: 0, Loss: 0.9722340621200263\n",
      "Epoch: 1, Loss: 0.9656457164708305\n",
      "Epoch: 2, Loss: 0.9545023382878771\n",
      "Epoch: 3, Loss: 0.9346802538516474\n",
      "Epoch: 4, Loss: 0.9075641024346445\n",
      "Epoch: 5, Loss: 0.8767649309307921\n",
      "Epoch: 6, Loss: 0.8424322979122985\n",
      "Epoch: 7, Loss: 0.8057672907324398\n",
      "Epoch: 8, Loss: 0.7696937521298727\n",
      "Epoch: 9, Loss: 0.734632690747579\n",
      "Epoch: 10, Loss: 0.7018912037213644\n",
      "Epoch: 11, Loss: 0.6698410429206549\n",
      "Epoch: 12, Loss: 0.6394874313298393\n",
      "Epoch: 13, Loss: 0.6110115390197903\n",
      "Epoch: 14, Loss: 0.584314576551026\n",
      "Epoch: 15, Loss: 0.559615996538424\n",
      "Epoch: 16, Loss: 0.5365763622171739\n",
      "Epoch: 17, Loss: 0.5155966550696129\n",
      "Epoch: 18, Loss: 0.4960978130499522\n",
      "Epoch: 19, Loss: 0.4774210599123263\n",
      "Epoch: 20, Loss: 0.4593783774796654\n",
      "Epoch: 21, Loss: 0.44203734865375593\n",
      "Epoch: 22, Loss: 0.42566709424935134\n",
      "Epoch: 23, Loss: 0.41062385954108893\n",
      "Epoch: 24, Loss: 0.3970618142801173\n",
      "Epoch: 25, Loss: 0.3847348298512253\n",
      "Epoch: 26, Loss: 0.37406464067159917\n",
      "Epoch: 27, Loss: 0.3647251777789172\n",
      "Epoch: 28, Loss: 0.35651175940738006\n",
      "Epoch: 29, Loss: 0.3491627568123387\n",
      "Epoch: 30, Loss: 0.34258468010846305\n",
      "Epoch: 31, Loss: 0.3365680972735087\n",
      "Epoch: 32, Loss: 0.3310021524335824\n",
      "Epoch: 33, Loss: 0.3256175576471815\n",
      "Epoch: 34, Loss: 0.3206351463701211\n",
      "Finished warmup in 65.87911081314087 seconds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss          \u001b[39m=\u001b[39m tsfm\u001b[39m.\u001b[39;49mfit(data_dict, n_epochs\u001b[39m=\u001b[39;49mN_EPOCHS, warmup_projection_layers\u001b[39m=\u001b[39;49mWARMUP_PROJECTION_LAYERS, \n\u001b[1;32m      2\u001b[0m                          log\u001b[39m=\u001b[39;49mLOG, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, warmup_epochs\u001b[39m=\u001b[39;49mWARMUP_EPOCHS, \n\u001b[1;32m      3\u001b[0m                          warmup_config_kwargs\u001b[39m=\u001b[39;49mwarmup_config_kwargs, warmup_batch_size\u001b[39m=\u001b[39;49mWARMUP_BATCH_SIZE,\n\u001b[1;32m      4\u001b[0m                          batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE, lr\u001b[39m=\u001b[39;49mLR, device\u001b[39m=\u001b[39;49mDEVICE, max_seq_length\u001b[39m=\u001b[39;49mMAX_SEQ_LENGTH, \n\u001b[1;32m      5\u001b[0m                         )\n",
      "File \u001b[0;32m~/TS-FM/src/TSFM.py:160\u001b[0m, in \u001b[0;36mTSFM.fit\u001b[0;34m(self, train_data_dict, labels, lr, n_epochs, batch_size, n_iters, verbose, shuffle, warmup_projection_layers, warmup_epochs, log, subset, configs, training_mode, warmup_config_kwargs, warmup_batch_size, print_every_iter, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTotal number of data points: \u001b[39m\u001b[39m{\u001b[39;00mtotal_number_of_data_points\u001b[39m}\u001b[39;00m\u001b[39m from \u001b[39m\u001b[39m{\u001b[39;00mall_dataset_names[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    159\u001b[0m \u001b[39m\"\"\"Warmup the projection layers\"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m datasets, optimizer_list, encoder_dataset_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwarmup(train_data_dict, warmup_projection_layers\u001b[39m=\u001b[39;49mwarmup_projection_layers, \n\u001b[1;32m    161\u001b[0m                                                              warmup_epochs\u001b[39m=\u001b[39;49mwarmup_epochs, shuffle\u001b[39m=\u001b[39;49mshuffle, \n\u001b[1;32m    162\u001b[0m                                                              warmup_config_kwargs\u001b[39m=\u001b[39;49mwarmup_config_kwargs, warmup_batch_size\u001b[39m=\u001b[39;49mwarmup_batch_size, \n\u001b[1;32m    163\u001b[0m                                                              lr\u001b[39m=\u001b[39;49mlr, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    164\u001b[0m                                                              )\n\u001b[1;32m    166\u001b[0m \u001b[39m\"\"\"Disable revIN for univariate forcasting\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39munivariate\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprojection_layers\u001b[39m.\u001b[39mkeys():\n",
      "File \u001b[0;32m~/TS-FM/src/TSFM.py:282\u001b[0m, in \u001b[0;36mTSFM.warmup\u001b[0;34m(self, train_data_dict, labels, lr, n_epochs, n_iters, verbose, shuffle, warmup_projection_layers, warmup_epochs, log, subset, configs, training_mode, warmup_config_kwargs, warmup_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m     batch_size \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m20\u001b[39m\n\u001b[1;32m    281\u001b[0m warmup_config \u001b[39m=\u001b[39m warmup_config_kwargs[dataset_name]\n\u001b[0;32m--> 282\u001b[0m dataset \u001b[39m=\u001b[39m warmup_config[\u001b[39m'\u001b[39;49m\u001b[39mdata_set_type\u001b[39;49m\u001b[39m'\u001b[39;49m](train_data, labels\u001b[39m=\u001b[39;49mlabels, shuffle\u001b[39m=\u001b[39;49mshuffle, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    283\u001b[0m n_epochs \u001b[39m=\u001b[39m warmup_epochs \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mn_epochs\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m warmup_config \u001b[39melse\u001b[39;00m warmup_config[\u001b[39m'\u001b[39m\u001b[39mn_epochs\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    284\u001b[0m batch_s  \u001b[39m=\u001b[39m batch_size \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m warmup_config \u001b[39melse\u001b[39;00m warmup_config[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/TS-FM/src/dataset.py:147\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, data, labels, mean_mask_length, masking_ratio, mode, distribution, exclude_feats, max_len, mask_compensation, pad_inputs, mask_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     # Preprocess the data by applying collate_unsuperv function for each sample\n\u001b[1;32m    144\u001b[0m     self.preprocessed_data = self._preprocess_data_parallel(data)\n\u001b[1;32m    146\u001b[0m def _preprocess_data_parallel(self, data):\n\u001b[0;32m--> 147\u001b[0m     # Define a function to preprocess a single sample\n\u001b[1;32m    148\u001b[0m     def preprocess_sample(ind):\n\u001b[1;32m    149\u001b[0m         X = data[ind]\n",
      "File \u001b[0;32m~/TS-FM/src/dataset.py:422\u001b[0m, in \u001b[0;36mnoise_mask\u001b[0;34m(X, masking_ratio, lm, mode, distribution, exclude_feats)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnoise_mask\u001b[39m(X, masking_ratio, lm\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mseparate\u001b[39m\u001b[39m'\u001b[39m, distribution\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgeometric\u001b[39m\u001b[39m'\u001b[39m, exclude_feats\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    409\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[39m    Creates a random boolean mask of the same shape as X, with 0s at places where a feature should be masked.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[39m        X: (seq_length, feat_dim) numpy array of features corresponding to a single sample\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[39m        masking_ratio: proportion of seq_length to be masked. At each time step, will also be the proportion of\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[39m            feat_dim that will be masked on average\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[39m        lm: average length of masking subsequences (streaks of 0s). Used only when `distribution` is 'geometric'.\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[39m        mode: whether each variable should be masked separately ('separate'), or all variables at a certain positions\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m            should be masked concurrently ('concurrent')\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[39m        distribution: whether each mask sequence element is sampled independently at random, or whether\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[39m            sampling follows a markov chain (and thus is stateful), resulting in geometric distributions of\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39m            masked squences of a desired mean length `lm`\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[39m        exclude_feats: iterable of indices corresponding to features to be excluded from masking (i.e. to remain all 1s)\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m \n\u001b[1;32m    423\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[39m        boolean numpy array with the same shape as X, with 0s at places where a feature should be masked\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    426\u001b[0m     \u001b[39mif\u001b[39;00m exclude_feats \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    427\u001b[0m         exclude_feats \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(exclude_feats)\n",
      "File \u001b[0;32m~/TS-FM/src/dataset.py:457\u001b[0m, in \u001b[0;36mgeom_noise_mask_single\u001b[0;34m(L, lm, masking_ratio)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgeom_noise_mask_single\u001b[39m(L, lm, masking_ratio):\n\u001b[1;32m    449\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    Randomly create a boolean mask of length `L`, consisting of subsequences of average length lm, masking with 0s a `masking_ratio`\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39m    proportion of the sequence L. The length of masking subsequences and intervals follow a geometric distribution.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m        L: length of mask and sequence to be masked\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39m        lm: average length of masking subsequences (streaks of 0s)\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[39m        masking_ratio: proportion of L to be masked\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \n\u001b[0;32m--> 457\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[39m        (L,) boolean numpy array intended to mask ('drop') with 0s a sequence of length L\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     keep_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(L, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m    461\u001b[0m     p_m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m lm  \u001b[39m# probability of each masking sequence stopping. parameter of geometric distribution.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "loss          = tsfm.fit(data_dict, n_epochs=N_EPOCHS, warmup_projection_layers=WARMUP_PROJECTION_LAYERS, \n",
    "                         log=LOG, verbose=True, shuffle=True, warmup_epochs=WARMUP_EPOCHS, \n",
    "                         warmup_config_kwargs=warmup_config_kwargs, warmup_batch_size=WARMUP_BATCH_SIZE,\n",
    "                         batch_size=BATCH_SIZE, lr=LR, device=DEVICE, max_seq_length=MAX_SEQ_LENGTH, \n",
    "                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6d400df1f0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in loss.keys():\n",
    "    plt.figure()\n",
    "    plt.title(key)\n",
    "    plt.plot( loss[key] )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
