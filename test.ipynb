{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchsummary\n",
    "# !pip install torchinfo\n",
    "# !pip install lumnisfactors\n",
    "# !pip install matplotlib\n",
    "# !pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import grequests\n",
    "\n",
    "from src.mvts_transformer.ts_transformer import TSTransformerEncoder, model_factory\n",
    "from src.utils import create_3d_array, standardize, rolling_mean_diff\n",
    "from src.projection_layers import LSTMMaskedAutoencoderProjection\n",
    "from src.dataset import TSDataset, ImputationDataset\n",
    "from src.dataloader import TSDataLoader\n",
    "from src.TFC.dataloader import TFCDataset\n",
    "from src.encoders import TFC\n",
    "from src.configs import Configs\n",
    "from src.RevIN import RevIN\n",
    "from src.TSFM import TSFM\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.fft as fft\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torchinfo import summary\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lumnisfactors import LumnisFactors\n",
    "from KEYS import LUMNIS_API_KEY\n",
    "\n",
    "factorName          = \"price\"\n",
    "lumnis              = LumnisFactors(LUMNIS_API_KEY)\n",
    "temp_df_btc_raw     = lumnis.get_historical_data(factorName, \"binance\", \"btcusdt\",  \"hour\", \"2021-01-23\", \"2023-04-16\")\n",
    "temp_df_eth_raw     = lumnis.get_historical_data(factorName, \"binance\", \"ethusdt\",  \"hour\", \"2021-01-23\", \"2023-04-16\")\n",
    "temp_df_xmr_raw     = lumnis.get_historical_data(factorName, \"binance\", \"xmrusdt\",  \"hour\", \"2021-01-23\", \"2023-04-16\")\n",
    "ob_df_raw           = lumnis.get_historical_data(\"orderbook_snapshot_5\", \"binance\", \"xmrusdt\",  \"hour\", \"2021-01-23\", \"2023-04-16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df_btc         = rolling_mean_diff(temp_df_btc_raw, [ 5, 25, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], type='standard')\n",
    "temp_df_eth         = rolling_mean_diff(temp_df_eth_raw, [ 5, 25, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], type='standard')\n",
    "temp_df_xmr         = rolling_mean_diff(temp_df_xmr_raw, [ 5, 25, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], type='standard')\n",
    "\n",
    "\n",
    "cols                = temp_df_btc.columns #['close', 'volume'] #\n",
    "max_seq_len         = 50\n",
    "\n",
    "btc_array           = create_3d_array(temp_df_btc[cols], temp_df_btc.index, max_seq_len)\n",
    "eth_array           = create_3d_array(temp_df_eth[cols], temp_df_eth.index, max_seq_len)\n",
    "xmr_array           = create_3d_array(temp_df_xmr[cols], temp_df_xmr.index, max_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your data as a dictionary\n",
    "data_dict = {\n",
    "    'dataset_btc': torch.from_numpy( btc_array).to(torch.float32),\n",
    "    'dataset_eth': torch.from_numpy( eth_array).to(torch.float32),\n",
    "    'dataset_xmr': torch.from_numpy( xmr_array).to(torch.float32)\n",
    "}\n",
    "\n",
    "# Create instances of TSDataset for each dataset\n",
    "datasets = {name: ImputationDataset(data) for name, data in data_dict.items()}\n",
    "\n",
    "# Create an instance of the custom data loader\n",
    "ts_data_loader = TSDataLoader(datasets, batch_size=64, max_len=max_seq_len)\n",
    "\n",
    "num_epochs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_shapes_dict  = {name: data.shape[1:] for name, data in data_dict.items()}\n",
    "\n",
    "encoder_configs         = Configs(TSlength_aligned=max_seq_len, \n",
    "                                    features_len=data_dict['dataset_btc'].shape[-1], \n",
    "                                    features_len_f=data_dict['dataset_btc'].shape[-1], \n",
    "                                    n_head=1,\n",
    "                                    dim_feedforward=128,\n",
    "                                    num_transformer_layers=1,\n",
    "                                    encoder_layer_dims=128,\n",
    "                                    linear_encoder_dim=256,\n",
    "                                    channel_output_size=10,\n",
    "                                    time_output_size=10,\n",
    "                                    d_model=128,\n",
    "                                    pos_encoding='learnable',\n",
    "                                    transformer_activation='gelu',\n",
    "                                    transformer_normalization_layer='BatchNorm',\n",
    "                                    freeze=False,\n",
    "                                )\n",
    "\n",
    "tsfm                    = TSFM(input_data_shapes_dict, \n",
    "                                batch_size=128, \n",
    "                                lr=1e-3, \n",
    "                                log=True, \n",
    "                                device='cpu',\n",
    "                                max_seq_length=max_seq_len,\n",
    "                                encoder_config=encoder_configs\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abuj/Documents/GitHub/TS-FM/src/TSFM.py:133: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_62dm4livko/croot/pytorch_1675190252673/work/aten/src/ATen/native/IndexingUtils.h:28.)\n",
      "  train_data             = train_data[~np.isnan(train_data).all(axis=2).all(axis=1)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary ~: 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m\n\u001b[1;32m      1\u001b[0m warmup_config_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdataset_btc\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[1;32m      3\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m128\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     }\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     19\u001b[0m data_set_type \u001b[39m=\u001b[39m ImputationDataset \u001b[39m# Make the ability to infer dataset type based on projection layer \u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m loss          \u001b[39m=\u001b[39m tsfm\u001b[39m.\u001b[39;49mfit(data_dict, n_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, warmup_projection_layers\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, log\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, warmup_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, warmup_config_kwargs\u001b[39m=\u001b[39;49mwarmup_config_kwargs, warmup_batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, data_set_type\u001b[39m=\u001b[39;49mdata_set_type)\n",
      "File \u001b[0;32m~/Documents/GitHub/TS-FM/src/TSFM.py:199\u001b[0m, in \u001b[0;36mTSFM.fit\u001b[0;34m(self, train_data_dict, labels, n_epochs, n_iters, verbose, shuffle, warmup_projection_layers, warmup_epochs, log, subset, configs, training_mode, warmup_config_kwargs, data_set_type, warmup_batch_size)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39mfor\u001b[39;00m dataset_name, data \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 199\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(data, dataset_name, optimizer, enocder_dataset_type)\n\u001b[1;32m    200\u001b[0m     cum_loss_dict[dataset_name] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    202\u001b[0m n_epoch_iters \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/TS-FM/src/TSFM.py:224\u001b[0m, in \u001b[0;36mTSFM.train_step\u001b[0;34m(self, data, dataset_name, optimizer, data_set_type)\u001b[0m\n\u001b[1;32m    220\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder_layer \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mTFC\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 224\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_step_TFC(data, dataset_name, data_set_type)\n\u001b[1;32m    226\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    227\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Documents/GitHub/TS-FM/src/TSFM.py:248\u001b[0m, in \u001b[0;36mTSFM._train_step_TFC\u001b[0;34m(self, batch, dataset_name, data_set_type)\u001b[0m\n\u001b[1;32m    245\u001b[0m aug1_f                              \u001b[39m=\u001b[39m DataTransform_FD(x_data_f, config)\n\u001b[1;32m    247\u001b[0m \u001b[39m# Produce embeddings\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m h_t, z_t, h_f, z_f                  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_encoder(x_data, x_data_f, padding_masks)\n\u001b[1;32m    249\u001b[0m h_t_aug, z_t_aug, h_f_aug, z_f_aug  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encoder(aug1, aug1_f, padding_masks)\n\u001b[1;32m    251\u001b[0m \u001b[39m# Compute Pre-train loss\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[39m# NTXentLoss: normalized temperature-scaled cross entropy loss. From SimCLR\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/baseline/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/TS-FM/src/encoders.py:74\u001b[0m, in \u001b[0;36mTFC.forward\u001b[0;34m(self, x_in_t, x_in_f, padding_masks)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x_in_t: torch\u001b[39m.\u001b[39mTensor, x_in_f: torch\u001b[39m.\u001b[39mTensor, padding_masks: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m    Perform forward pass for the TFC module.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m        Tuple containing h_time, z_time, h_freq, and z_freq tensors.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder_t(x_in_t, padding_masks)\n\u001b[1;32m     75\u001b[0m     h_time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madaptive_pool_t(x)\n\u001b[1;32m     77\u001b[0m     z_time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprojector_t(h_time)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/baseline/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/TS-FM/src/mvts_transformer/ts_transformer.py:241\u001b[0m, in \u001b[0;36mTSTransformerEncoder.forward\u001b[0;34m(self, X, padding_masks)\u001b[0m\n\u001b[1;32m    239\u001b[0m inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_enc(inp)  \u001b[39m# add positional encoding\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m# NOTE: logic for padding masks is reversed to comply with definition in MultiHeadAttention, TransformerEncoderLayer\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_encoder(inp, src_key_padding_mask\u001b[39m=\u001b[39m\u001b[39m~\u001b[39;49mpadding_masks)  \u001b[39m# (seq_length, batch_size, d_model)\u001b[39;00m\n\u001b[1;32m    242\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(output)  \u001b[39m# the output transformer encoder/decoder embeddings don't include non-linearity\u001b[39;00m\n\u001b[1;32m    243\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)  \u001b[39m# (batch_size, seq_length, d_model)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary ~: 'NoneType'"
     ]
    }
   ],
   "source": [
    "warmup_config_kwargs = {\n",
    "    \"dataset_btc\": {\n",
    "        \"batch_size\": 128,\n",
    "        \"input_channels\": data_dict['dataset_btc'].shape[-1],\n",
    "        \"timesteps\": data_dict['dataset_btc'].shape[1],\n",
    "    },\n",
    "    \"dataset_eth\": {\n",
    "        \"batch_size\": 128,\n",
    "        \"input_channels\": data_dict['dataset_eth'].shape[-1],\n",
    "        \"timesteps\": data_dict['dataset_eth'].shape[1],\n",
    "    },\n",
    "    \"dataset_xmr\": {\n",
    "        \"batch_size\": 128,\n",
    "        \"input_channels\": data_dict['dataset_xmr'].shape[-1],\n",
    "        \"timesteps\": data_dict['dataset_xmr'].shape[1],\n",
    "    }\n",
    "}\n",
    "\n",
    "data_set_type = ImputationDataset # Make the ability to infer dataset type based on projection layer \n",
    "loss          = tsfm.fit(data_dict, n_epochs=10, warmup_projection_layers=False, log=True, verbose=True, shuffle=True, warmup_epochs=10, warmup_config_kwargs=warmup_config_kwargs, warmup_batch_size=128, data_set_type=data_set_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
